{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Generation Parameters Glossary\n",
    "**THIS IS A GLOSSARY MEANT TO BE A REFERENCE, THE CODE CELLS ARE NOT MEANT TO BE EXECUTED**\n",
    "\n",
    "Each sample to be fed to the Neural Network model is comprised of three elements, each contained in its own individual file:\n",
    "\n",
    "- **Graph topology**: Represents a graph topology, including the nodes and edges that forms it as well as characterstics of each.\n",
    "- **Routing file**: Shows the recognized paths between each node witin the graph topology.\n",
    "- **Traffic matrix (TM)**: Represents traffic flows going through a given network.\n",
    "\n",
    "Each sample will be identified by a tuple of these three elements. This means we can generate multiple samples from the same graph topology if it's paired with different traffic matrices, for example.\n",
    "\n",
    "In this notebook, we will show how to generate these files, and how their properties can be altered in order to generate different varying samples. Note that for a quick summary of all the constraints while generating the training dataset can be found at the [training_dataset_constraints](training_dataset_constraints.md) markdown file. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate, for instance, a complete graph\n",
    "G = nx.complete_graph(10)\n",
    "\n",
    "# Assign bandwidth to each edge of the graph. Its value is considered in bps.\n",
    "for (n0,n1) in G.edges():\n",
    "    G[n0][n1][\"bandwidth\"] = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each node is defined by two characteristics:\n",
    "- **Scheduling policy**. The order in which packets are served in an output port is based on the state of queues and the configured queue scheduling policy. We consider the following four policies:\n",
    "    - *First In First Out (FIFO)*: shared single queue for all packets, indepedently of ToSs.\n",
    "    - *Strict Priority (SP)*: one queue for each ToS (total of 3) were packets in queues with more priority are transmitted first.\n",
    "    - *Weighted Fair Queueing (WFQ)*: one queue for each ToS (total of 3). Each queue is assigned a weight by the configuration. *The sum of weights must equal 100*. Each time the policy chooses a queue according to its weight plus the data rate of the queue to achieve fairness.\n",
    "    - *Deficit Round Robin  (DRR)*: one queue for each ToS (total of 3). Each queue is assigned a weight by the configuration. *The sum of weights must equal 100*. The policy will cycle through the queues. The amount of time dedicated to each queue is proportional to its weight.\n",
    "- **Buffer size**: the size of the buffer at the output ports of nodes, where packets are stored before they are processed. When a packet is received and its outgoing queue is full, the packet is dropped. The buffer size is computed in bits and its value should be between 8000 and 64000 bits.\n",
    "\n",
    "We must define these two characterstics on all nodes of the topology. The scheduling policy of a node is stored in the attribute ```schedulingPolicy``` as a string. This is shown as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's configure all the nodes with a FIFO policy\n",
    "for node in G:\n",
    "    G.nodes[node][\"schedulingPolicy\"] = \"FIFO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's configure all the nodes with a SP policy\n",
    "for node in G:\n",
    "    G.nodes[node][\"schedulingPolicy\"] = \"SP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of the WFQ and DRR policies, where we will also need to specify the weights of each queue, we will also need to define the attribute ```schedulingWeights```. To do so, we will feed it a string that contains the weights for the queue dealing with ToS 0, 1, and 2, respectively, separated by commas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's configure all the nodes with a WFQ policy\n",
    "for node in G:\n",
    "    G.nodes[node][\"schedulingPolicy\"] = \"WFQ\"\n",
    "    G.nodes[node][\"schedulingWeights\"] = \"45, 30, 25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's configure all the nodes with a DRR policy\n",
    "for node in G:\n",
    "    G.nodes[node][\"schedulingPolicy\"] = \"DRR\"\n",
    "    G.nodes[node][\"schedulingWeights\"] = \"45, 30, 25\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure the buffer size we will only need to modify the attribute ```bufferSizes```, including the size of the queue in bits. As a reminder, its value should be between 8000 and 64000 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign to each node a queue size of 32000 bits\n",
    "for node in G:\n",
    "    G.nodes[node][\"bufferSizes\"] = 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we save the topology\n",
    "graph_file = \"graph.txt\"\n",
    "nx.write_gml(G,graph_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing\n",
    "The routing is expressed as a text file where each line represents a path as a sequence of nodes.\n",
    "Destination base and source destination base routing can be used but they should not contain loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For instance, we can use networkx to calculate the shortest path routing for each src-dst pair.\n",
    "with open(\"routing.txt\",\"w\") as r_fd:\n",
    "    lPaths = nx.shortest_path(G)\n",
    "    for src in G:\n",
    "        for dst in G:\n",
    "            if (src == dst):\n",
    "                continue\n",
    "            path =  ','.join(str(x) for x in lPaths[src][dst])\n",
    "            r_fd.write(path+\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic Matrix\n",
    "The final step is to generate the traffic matrix (TM). Each line of the TM file describes one traffic flow between two nodes. These lines are formed by a set of parameters separated by commas as follows:\n",
    "\n",
    "```source, destination, avg_bw, time_distribution, [on_time, off_time,] pkt_dist, pkt_size_1, prob_1, [pkt_size_2, prob_2, [pkt_size_3, prob_3, [pkt_size_4, prob_4, [pkt_size_5, prob_5,]]]] tos```\n",
    "\n",
    "Here the brackets indicate optional parameters. \n",
    "\n",
    "The ```source``` and ```destination``` parameters indicate the source and destination nodes for the given flow. Note that only one flow is allowed per source-destination pair in the input topology.\n",
    "\n",
    "The ```avg_bw``` parameter indicates the average bandwidth, in bps, to be generated for this flow. Its value is limited between 10 and 10000 bps.\n",
    "\n",
    "The next sets of parameters we'll discuss are ```pkt_dist```, ```pkt_size_n``` and ```prob_n```. These parameters are used to indicate the possible sizes of the packets and their relative frequency within the flow. ```pkt_dist``` specifically notes the distribution type used to generate the packets. **Note: currently only one distribution is supported, so the value of ```pkt_dist``` should aways be ```0```.**\n",
    "\n",
    "Then, the ```pkt_size_n``` and ```prob_n``` properties are used to indicate a packet size, in bits, and its relative probability with respect to the other sizes. At least one packet size must be declared, but we can define up to 5 different sizes. The packet size should be a value between 256 and 2000 bits while the sum of all the ```prob_n``` values should equal 1.\n",
    "\n",
    "The ```time_distribution``` parameter indicates how often packets should be generated over time. We support three time distributions:\n",
    "- *Poisson* (```time_distribution```=0): packets are generated following a Poisson distribution\n",
    "- *CBR* (```time_distribution```=1): packets are generated following a Continous Bit Rate model\n",
    "- *ON-OFF* (```time_distribution```=2): packets are generated following periods of activity and inactivity\n",
    "\n",
    "We do *NOT* need to define the parameters that define Poisson and CBR distributions, as the packets will be generated considering the chosen packet size distribution and average bandwith parameters from earlier. In the case of using the ON-OFF distribution we will need to define the length of the activity and inactivity periods (```on_time``` and ```off_time``` respectively).\n",
    "\n",
    "Finally, ```tos``` indicates the ToS assigned to the packets generated for this flow, with values of 0, 1 or 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example: this code will generate flows between all nodes in the graph, such as:\n",
    "- The average bandwidth is randomized between 10 and 10000 bps\n",
    "- An ON-OFF time distribution is used, with an on_time of 5 s and an off_time of 10 s\n",
    "- Packets can have two possible sizes, 300 and 1700 bits, both equally probable\n",
    "- The ToS for all flows is 0 (high priority)\n",
    "\"\"\"\n",
    "with open(\"traffic.txt\",\"w\") as tm_fd:\n",
    "    for src in G:\n",
    "        for dst in G:\n",
    "            avg_bw = random.randint(10,10000)\n",
    "            time_dist = 2\n",
    "            on_time = 5\n",
    "            off_time = 10\n",
    "            pkt_size_1 = 300\n",
    "            prob_1 = 0.5\n",
    "            pkt_size_2 = 1700\n",
    "            prob_2 = 0.5\n",
    "            tos = 0\n",
    "            traffic_line = \"{},{},{},{},{},{},0,{},{},{},{},{}\".format(\n",
    "                src,dst,avg_bw,time_dist,on_time,off_time,pkt_size_1,\n",
    "                prob_1,pkt_size_2,prob_2,tos)\n",
    "            tm_fd.write(traffic_line+\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4fabe4be1dcb5b95007215d13ed47b80f9ccf78939eea74ae4a681230c3cbef"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('BNNChallenge2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}